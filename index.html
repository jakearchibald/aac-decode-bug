<!doctype html>
<meta name="viewport" content="width=device-width, minimum-scale=1.0">
<style>
  .audio-container {
    position: relative;
  }
  .audio-output {
    position: relative;
    height: 200px;
    background: #45b35a;
  }
  .audio-output > * {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
  }
  .aac-decode {
    display: flex;
  }
  .aac-decode .audio-output {
    flex: 1;
  }
  .aac-decode .audio-output:first-child {
    margin-right: 5px;
  }
  .aac-decode .audio-output:last-child {
    margin-left: 5px;
  }
</style>
<script>
function bufferFetch(url, progressCb) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    xhr.responseType = 'arraybuffer';
    xhr.onload = () => resolve(xhr.response); 
    xhr.onerror = () => reject(Error('Fetch failed'));
    if (progressCb) xhr.onprogress = event => progressCb(event.loaded / event.total);
    xhr.open('GET', url);
    xhr.send();
  });
}

const context = new (self.AudioContext || self.webkitAudioContext)();

function drawAudio(canvas, buffer, start, end) {
  const resolution = 50;
  const rect = canvas.getBoundingClientRect();
  canvas.width = Math.floor(rect.width * devicePixelRatio);
  canvas.height = Math.floor(rect.height * devicePixelRatio);
  const context = canvas.getContext('2d');
  let data = buffer.getChannelData(0);

  if (start || end) {
    data = data.slice(start || 0, end || data.length);
  }

  context.fillStyle = '#7bf792';

  for (let i = 0; i < canvas.width; i++) {
    let max = -Infinity;
    let min = Infinity;
    const start = Math.floor(i / canvas.width * data.length);
    const end = Math.floor((i+1) / canvas.width * data.length);
    const interval = Math.floor((end - start) / resolution) || 1;

    for (let j = start; j <= end; j += interval) {
      const item = data[j];
      if (max < item) max = item;
      if (min > item) min = item;
    }

    const height = (max - min) / 2 * canvas.height;
    const startPixel = (1 - (max + 1) / 2) * canvas.height;

    context.fillRect(i, startPixel, 1, height)
  }
}

function getStartGap(buffer) {
  const l = buffer.getChannelData(0);
  const r = buffer.getChannelData(1);

  for (var i = 0; i < l.length; i++) {
    if (l[i] || r[i]) break;
  }    
  return i;
}

function getEndGap(buffer) {
  const l = buffer.getChannelData(0);
  const r = buffer.getChannelData(1);

  for (var i = l.length; i >= 0; i--) {
    if (l[i] || r[i]) break;
  }    
  return l.length - i;
}

// Safari doesn't support promises in decodeAudioData :(
if (!window.AudioContext && window.webkitAudioContext) {
  const oldFunc = webkitAudioContext.prototype.decodeAudioData;
  webkitAudioContext.prototype.decodeAudioData = function(arraybuffer) {
    return new Promise((resolve, reject) => {
      oldFunc.call(this, arraybuffer, resolve, reject);
    });
  }
}
</script>
<h1><a href="tiny-clip.wav">Original WAV</a></h1>
<div class="audio-container">
  <div class="aac-decode">
    <div class="audio-output">
      <canvas></canvas>
    </div>
    <div class="audio-output">
      <canvas></canvas>
    </div>
  </div>
</div>
<p class="start-gap-wav">Start gap: </p>
<p class="end-gap-wav">End gap: </p>
<script>
bufferFetch('tiny-clip.wav').then(ab => context.decodeAudioData(ab)).then(buffer => {
  const canvases = document.querySelectorAll('.aac-decode canvas');
  drawAudio(canvases[0], buffer, 0, 7000);
  drawAudio(canvases[1], buffer, -7000);
  document.querySelector('.start-gap-wav').textContent += `${getStartGap(buffer)} samples`;
  document.querySelector('.end-gap-wav').textContent += `${getEndGap(buffer)} samples`;
});
</script>
<h1><a href="tiny-clip.mp4">AAC</a></h1>
<p>Encoded using <code>afconvert -s 3 -f mp4f tiny-clip.wav</code></p>
<div class="audio-container">
  <div class="aac-decode">
    <div class="audio-output">
      <canvas></canvas>
    </div>
    <div class="audio-output">
      <canvas></canvas>
    </div>
  </div>
</div>
<p class="start-gap-aac">Start gap: </p>
<p class="end-gap-aac">End gap: </p>
<script>
bufferFetch('tiny-clip.mp4').then(ab => context.decodeAudioData(ab)).then(buffer => {
  const canvases = document.querySelectorAll('.aac-decode canvas');
  drawAudio(canvases[2], buffer, 0, 7000);
  drawAudio(canvases[3], buffer, -7000);
  document.querySelector('.start-gap-aac').textContent += `${getStartGap(buffer)} samples`;
  document.querySelector('.end-gap-aac').textContent += `${getEndGap(buffer)} samples`;
});
</script>
<h1><a href="tiny-clip.opus">Opus</a></h1>
<div class="audio-container">
  <div class="aac-decode">
    <div class="audio-output">
      <canvas></canvas>
    </div>
    <div class="audio-output">
      <canvas></canvas>
    </div>
  </div>
</div>
<p class="start-gap-opus">Start gap: </p>
<p class="end-gap-opus">End gap: </p>
<script>
bufferFetch('tiny-clip.opus').then(ab => context.decodeAudioData(ab)).then(buffer => {
  const canvases = document.querySelectorAll('.aac-decode canvas');
  drawAudio(canvases[4], buffer, 0, 7000);
  drawAudio(canvases[5], buffer, -7000);
  document.querySelector('.start-gap-opus').textContent += `${getStartGap(buffer)} samples`;
  document.querySelector('.end-gap-opus').textContent += `${getEndGap(buffer)} samples`;
});
</script>
<h1><a href="tiny-clip.ogg">Vorbis</a></h1>
<div class="audio-container">
  <div class="aac-decode">
    <div class="audio-output">
      <canvas></canvas>
    </div>
    <div class="audio-output">
      <canvas></canvas>
    </div>
  </div>
</div>
<p class="start-gap-ogg">Start gap: </p>
<p class="end-gap-ogg">End gap: </p>
<script>
bufferFetch('tiny-clip.ogg').then(ab => context.decodeAudioData(ab)).then(buffer => {
  const canvases = document.querySelectorAll('.aac-decode canvas');
  drawAudio(canvases[6], buffer, 0, 7000);
  drawAudio(canvases[7], buffer, -7000);
  document.querySelector('.start-gap-ogg').textContent += `${getStartGap(buffer)} samples`;
  document.querySelector('.end-gap-ogg').textContent += `${getEndGap(buffer)} samples`;
});
</script>
<h1><a href="tiny-clip.flac">FLAC</a></h1>
<div class="audio-container">
  <div class="aac-decode">
    <div class="audio-output">
      <canvas></canvas>
    </div>
    <div class="audio-output">
      <canvas></canvas>
    </div>
  </div>
</div>
<p class="start-gap-flac">Start gap: </p>
<p class="end-gap-flac">End gap: </p>
<script>
bufferFetch('tiny-clip.flac').then(ab => context.decodeAudioData(ab)).then(buffer => {
  const canvases = document.querySelectorAll('.aac-decode canvas');
  drawAudio(canvases[8], buffer, 0, 7000);
  drawAudio(canvases[9], buffer, -7000);
  document.querySelector('.start-gap-flac').textContent += `${getStartGap(buffer)} samples`;
  document.querySelector('.end-gap-flac').textContent += `${getEndGap(buffer)} samples`;
});
</script>
<h1><a href="tiny-clip.mp3">MP3</a></h1>
<div class="audio-container">
  <div class="aac-decode">
    <div class="audio-output">
      <canvas></canvas>
    </div>
    <div class="audio-output">
      <canvas></canvas>
    </div>
  </div>
</div>
<p class="start-gap-mp3">Start gap: </p>
<p class="end-gap-mp3">End gap: </p>
<script>
bufferFetch('tiny-clip.mp3').then(ab => context.decodeAudioData(ab)).then(buffer => {
  const canvases = document.querySelectorAll('.aac-decode canvas');
  drawAudio(canvases[10], buffer, 0, 7000);
  drawAudio(canvases[11], buffer, -7000);
  document.querySelector('.start-gap-mp3').textContent += `${getStartGap(buffer)} samples`;
  document.querySelector('.end-gap-mp3').textContent += `${getEndGap(buffer)} samples`;
});
</script>